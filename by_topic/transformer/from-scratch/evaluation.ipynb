{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"checkpoints-20230808/logs.txt\", header=None, names=['x', 'y', 'train_loss', 'val_loss', 'lr', 't'])\n",
    "display(df.head(1))\n",
    "\n",
    "df['train_loss'] = df.train_loss.apply(lambda x: float(x.split(\": \")[-1]))\n",
    "df['val_loss'] = df.val_loss.apply(lambda x: float(x.split(\": \")[-1]))\n",
    "df['lr'] = df.lr.apply(lambda x: float(x.split(\": \")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df.train_loss.values)\n",
    "plt.plot(df.val_loss.values)\n",
    "plt.legend([\"train loss\", \"val loss\"])\n",
    "plt.show()\n",
    "plt.plot(df.lr.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformer import Transformer, BOS_IDX, EOS_IDX, block_size, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "model.load_state_dict(torch.load('checkpoints-20230808/checkpoint-ep05.pt'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "tokenizers = {}\n",
    "for lang in ['en', 'es']:\n",
    "    tokenizers[lang] = Tokenizer.from_file(f\"tokenizer-{lang}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_transform(token_ids):\n",
    "    transformed =  torch.cat((\n",
    "        torch.tensor([BOS_IDX]),\n",
    "        torch.tensor(token_ids),\n",
    "        torch.tensor([EOS_IDX]))\n",
    "    )\n",
    "    if len(transformed.shape) == 1:\n",
    "        transformed = transformed[None, :]\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx_enc, greedy=False):\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    B = idx_enc.shape[0]\n",
    "    device = next(model.parameters()).device\n",
    "    idx = torch.ones(B,1).fill_(BOS_IDX).type(torch.long).to(device)\n",
    "    for i in range(block_size):\n",
    "    # for i in range(10):\n",
    "        # get the predictions\n",
    "        logits, _ = model(idx, idx_enc)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :] # becomes (B, C)\n",
    "        if greedy:\n",
    "            idx_next = torch.argmax(logits, dim=-1)\n",
    "        else:\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "        # make everything comes after 1st EOS an EOS\n",
    "        idx_next = torch.where(idx[:, -1]==EOS_IDX, EOS_IDX, idx_next.squeeze())\n",
    "        # append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next[:, None]), dim=1) # (B, T+1)\n",
    "        if torch.all(idx[:, -1]==EOS_IDX):\n",
    "            break\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"What a beautiful day!\",\n",
    "    \"This is the first deep learning model that I built from scratch.\",\n",
    "    \"You'll have to address any questions to my commanding officer.\",\n",
    "    \"The results of the project are clear.\",\n",
    "    \"I mean, my dad does business with them, or he raised money for them.\",\n",
    "    \"A 3-month-old died after he was left unattended in a vehicle in Houston\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in sents:\n",
    "    toks = tensor_transform(tokenizers['en'].encode(sent).ids).to(device)\n",
    "    toks_es = generate(model, toks, greedy=True)\n",
    "    sent_es = tokenizers['es'].decode(toks_es[0].tolist())\n",
    "    print(sent)\n",
    "    print(sent_es)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
