## Why We Think
Date of publish: May 2025
Authors: Lilian Weng
Tags:  #reasoning #LRM 

Talk link: https://youtu.be/ebnX5Ur1hBk
Paper link:  https://lilianweng.github.io/posts/2025-05-01-thinking/
Related: 
### Details
1. Branching and editing
2. RL for better reasoning
	1. "The DeepSeek team also shared some of their unsuccessful attempts..."

### My thoughts
1. Test time compute vs CoT
	1. Spend `Test time compute` on `CoT`?
## Stanford CS25: V5 I Large Language Model Reasoning
Date of publish: April 2025
Authors: Denny Zhou (Google Deepmind)
Tags: #LRM

Talk link: https://youtu.be/ebnX5Ur1hBk
Paper link:  
Related: 
### Why interesting
1. Major trends in reasoning model training

### References
1. [Chain of Thought Empowers Transformers to Solve Inherently Serial Problems](https://arxiv.org/pdf/2402.12875)
	1. Theoretical proof of COT

