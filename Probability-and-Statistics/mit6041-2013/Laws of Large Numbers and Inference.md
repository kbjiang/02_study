Date: 2024-05-08
Course:
Chapter: 
Lecture: 
Topic: #Probability #LawsOfLargeNumber

## Lectures
### Lecture 19: Weak Law of Large Numbers
1. It considers *long sequence* of identical independent R.V.s. 
	1. Sample mean $M_n$ is average of $n$ samples from one sampling process (one experiment)
	2. Expectation $\mathbf{E}[M_n]$ is average of infinite $M_n$
	3. But we usually concerns with $\mathbf{P}(M_n)$ where $M_n$ is a single experiment and ask the likelihood of it being in some interval?
2. Markov/Chebyshev Inequality
	1. links expectation/expectation and variance with probability
		1. Useful when mean and variance are easy to compute but dist. is hard to get
	2. valid for *ANY* R.V.s.
3. The Weak Law of Large Numbers
	1. Is an application of Chebyshev. *Only* deals with sample mean R.V.
4. Convergence in Probability however can be about any R.V.
	1. $Y_n$ converges in probability $\nRightarrow$ $\mathbf{E}[Y_n]$ converges too. See Example 5.8, page 272.
5. The example of Y_n = {0, n} at lec. vid. 23:00
6. intuition leads to CLT around 40:30
## My comments
1. Chebyshev is for any R.V., while Weak LLN is specific for sample mean R.V.
## Interesting/Challenging problems and tricks
1. 